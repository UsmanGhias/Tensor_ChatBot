{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e1ed391-146a-466e-98fe-73ac229ba751",
   "metadata": {},
   "source": [
    "# $$ Interacting With the Chatbot $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a33372-6054-4b42-a473-55c4f153ee6d",
   "metadata": {},
   "source": [
    "1. Import necessary libraries:\n",
    "   - `tkinter` for creating the GUI.\n",
    "   - Your pre-trained chatbot model.\n",
    "   - Other relevant libraries for processing user input and generating responses.\n",
    "\n",
    "2. Create the GUI structure:\n",
    "   - Design the user interface with an input box for user messages and an area for displaying chat history.\n",
    "\n",
    "3. Define functions for processing user input:\n",
    "   - When the user enters a message, preprocess it (e.g., tokenize and lemmatize) to prepare it for the model.\n",
    "   - Use your pre-trained model to predict the intent of the user's message.\n",
    "   - Randomly select a response from the list of responses for that intent.\n",
    "\n",
    "4. Display the chat:\n",
    "   - Show the user's input and the chatbot's response in the chat history area.\n",
    "   - Update the chat history as the conversation progresses.\n",
    "\n",
    "5. Handle user interactions:\n",
    "   - Allow the user to enter messages and receive responses.\n",
    "   - Implement a way to end the conversation or exit the GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b759a1-8157-4aa1-9f40-b46ae20bd073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db033678-0320-42f9-87d1-a78c74d6f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('chatbot_model.h5')\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a844a65-3169-4d3c-b75a-77cb4aa20175",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = json.loads(open('intents.json').read())\n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20027152-7f56-44e6-8967-2bcf5db122fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf624f8-4dcd-4897-a4eb-3c541515b6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d28dc23-605f-4a6c-b7e1-1983d1280759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for words in sentence_words]\n",
    "    return sentence_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b1f2be-fd0d-446e-987e-1d211c742625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1946fdf-8a41-451f-8c2a-dfd55a5b7252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(sentence, words, show_details = True):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0]*len(words)\n",
    "\n",
    "    for s in sentence_words()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6cddd-b4c7-4887-b84c-0b80756b3c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39855b-2fdb-4a75-b112-098fb378b04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
